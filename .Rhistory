df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x=term, y=freq)) + geom_bar(stat="identity") +
xlab("Terms") + ylab("Count") + coord_flip() +
theme(axis.text=element_text(size=7))
myCorpus <- lapply(myCorpus, stemCompletion2, dictionary=myCorpusCopy)
tdm <- TermDocumentMatrix(myCorpus,
control = list(wordLengths = c(1, Inf)))
tdm
idx <- which(dimnames(tdm)$Terms %in% c("r", "data", "mining"))
as.matrix(tdm[idx, 21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 20)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x=term, y=freq)) + geom_bar(stat="identity") +
xlab("Terms") + ylab("Count") + coord_flip() +
theme(axis.text=element_text(size=7))
VectorSource(myCorpus)
myCorpus2 <- Corpus(VectorSource(myCorpus))
?VectorSource
wordFreq <- function(corpus, word)
{
results <- lapply(corpus, function(x) {
grep(as.character(x), pattern=paste0("\\<",word))
})
sum(unlist(results))
}
n.miner <- wordFreq(myCorpusCopy, "miner")
n.mining <- wordFreq(myCorpusCopy, "mining")
cat(n.miner, n.mining)
## 9 104
# replace oldword with newword
replaceWord <- function(corpus, oldword, newword)
{
tm_map(corpus, content_transformer(gsub),
pattern=oldword, replacement=newword)
}
myCorpus <- replaceWord(myCorpus, "miner", "mining")
myCorpus <- replaceWord(myCorpus, "universidad", "university")
myCorpus <- replaceWord(myCorpus, "scienc", "science")
tdm <- TermDocumentMatrix(myCorpus,
control = list(wordLengths = c(1, Inf)))
tdm
idx <- which(dimnames(tdm)$Terms %in% c("r", "data", "mining"))
as.matrix(tdm[idx, 21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 20)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x=term, y=freq)) + geom_bar(stat="identity") +
xlab("Terms") + ylab("Count") + coord_flip() +
theme(axis.text=element_text(size=7))
myCorpus <- Corpus(VectorSource(myCorpus))
writeLines(strwrap(myCorpus[[190]]$content, 60))
wordFreq <- function(corpus, word)
{
results <- lapply(corpus, function(x) {
grep(as.character(x), pattern=paste0("\\<",word))
})
sum(unlist(results))
}
n.miner <- wordFreq(myCorpusCopy, "miner")
n.mining <- wordFreq(myCorpusCopy, "mining")
cat(n.miner, n.mining)
## 9 104
# replace oldword with newword
replaceWord <- function(corpus, oldword, newword)
{
tm_map(corpus, content_transformer(gsub),
pattern=oldword, replacement=newword)
}
myCorpus <- replaceWord(myCorpus, "miner", "mining")
myCorpus <- replaceWord(myCorpus, "universidad", "university")
myCorpus <- replaceWord(myCorpus, "scienc", "science")
tdm <- TermDocumentMatrix(myCorpus,
control = list(wordLengths = c(1, Inf)))
tdm
idx <- which(dimnames(tdm)$Terms %in% c("r", "data", "mining"))
as.matrix(tdm[idx, 21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 20)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x=term, y=freq)) + geom_bar(stat="identity") +
xlab("Terms") + ylab("Count") + coord_flip() +
theme(axis.text=element_text(size=7))
tweets <- readRDS("~/trabajo/massa/twitter/yanchang/RDataMining-Tweets-20160212.rds")
length(tweets)
tweets.df <- twListToDF(tweets)
tweets.df[190, c("id", "created", "screenName", "replyToSN",
"favoriteCount", "retweetCount", "longitude", "latitude", "text")]
writeLines(strwrap(tweets.df$text[190], 60))
myCorpus <- Corpus(VectorSource(tweets.df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeURL))
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeNumPunct))
# remove stopwords
myStopwords <- c(setdiff(stopwords('english'), c("r", "big")),"use", "see", "used", "via", "amp")
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
# remove extra whitespace
myCorpus <- tm_map(myCorpus, stripWhitespace)
# keep a copy for stem completion later
myCorpusCopy <- myCorpus
myCorpus <- tm_map(myCorpus, stemDocument)
# stem words
writeLines(strwrap(myCorpus[[190]]$content, 60))
stemCompletion2 <- function(x, dictionary)
{
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""]
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
myCorpus <- lapply(myCorpus, stemCompletion2, dictionary=myCorpusCopy)
library(graph)
library(Rgraphviz)
install.packages("Rgraphviz")
source("http://bioconductor.org/biocLite.R")
biocLite("Rgraphviz")
library(Rgraphviz)
plot(tdm, term = freq.terms, corThreshold = 0.1, weighting = T)
tweets <- readRDS("~/trabajo/massa/twitter/yanchang/RDataMining-Tweets-20160212.rds")
length(tweets)
tweets.df <- twListToDF(tweets)
tweets.df[190, c("id", "created", "screenName", "replyToSN",
"favoriteCount", "retweetCount", "longitude", "latitude", "text")]
writeLines(strwrap(tweets.df$text[190], 60))
myCorpus <- Corpus(VectorSource(tweets.df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeURL))
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeNumPunct))
# remove stopwords
myStopwords <- c(setdiff(stopwords('english'), c("r", "big")),"use", "see", "used", "via", "amp")
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
# remove extra whitespace
myCorpus <- tm_map(myCorpus, stripWhitespace)
# keep a copy for stem completion later
myCorpusCopy <- myCorpus
myCorpus <- tm_map(myCorpus, stemDocument)
# stem words
writeLines(strwrap(myCorpus[[190]]$content, 60))
stemCompletion2 <- function(x, dictionary)
{
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""]
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
myCorpus <- lapply(myCorpus, stemCompletion2, dictionary=myCorpusCopy)
class(myCorpus)
wordFreq <- function(corpus, word)
{
results <- lapply(corpus, function(x) {
grep(as.character(x), pattern=paste0("\\<",word))
})
sum(unlist(results))
}
n.miner <- wordFreq(myCorpusCopy, "miner")
n.mining <- wordFreq(myCorpusCopy, "mining")
cat(n.miner, n.mining)
## 9 104
# replace oldword with newword
replaceWord <- function(corpus, oldword, newword)
{
tm_map(corpus, content_transformer(gsub),
pattern=oldword, replacement=newword)
}
myCorpus <- replaceWord(myCorpus, "miner", "mining")
myCorpus <- replaceWord(myCorpus, "universidad", "university")
myCorpus <- replaceWord(myCorpus, "scienc", "science")
tdm <- TermDocumentMatrix(myCorpus,
control = list(wordLengths = c(1, Inf)))
tdm
idx <- which(dimnames(tdm)$Terms %in% c("r", "data", "mining"))
as.matrix(tdm[idx, 21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 20)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x=term, y=freq)) + geom_bar(stat="identity") +
xlab("Terms") + ylab("Count") + coord_flip() +
theme(axis.text=element_text(size=7))
tweets <- readRDS("~/trabajo/massa/twitter/yanchang/RDataMining-Tweets-20160212.rds")
length(tweets)
tweets.df <- twListToDF(tweets)
tweets.df[190, c("id", "created", "screenName", "replyToSN",
"favoriteCount", "retweetCount", "longitude", "latitude", "text")]
writeLines(strwrap(tweets.df$text[190], 60))
myCorpus <- Corpus(VectorSource(tweets.df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeURL))
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeNumPunct))
# remove stopwords
myStopwords <- c(setdiff(stopwords('english'), c("r", "big")),"use", "see", "used", "via", "amp")
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
# remove extra whitespace
myCorpus <- tm_map(myCorpus, stripWhitespace)
# keep a copy for stem completion later
myCorpusCopy <- myCorpus
myCorpus <- tm_map(myCorpus, stemDocument)
# stem words
writeLines(strwrap(myCorpus[[190]]$content, 60))
stemCompletion2 <- function(x, dictionary)
{
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""]
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
myCorpus <- lapply(myCorpus, stemCompletion2, dictionary=myCorpusCopy)
tdm <- TermDocumentMatrix(myCorpus,
control = list(wordLengths = c(1, Inf)))
tdm
idx <- which(dimnames(tdm)$Terms %in% c("r", "data", "mining"))
as.matrix(tdm[idx, 21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 20)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x=term, y=freq)) + geom_bar(stat="identity") +
xlab("Terms") + ylab("Count") + coord_flip() +
theme(axis.text=element_text(size=7))
tweets <- readRDS("~/trabajo/massa/twitter/yanchang/RDataMining-Tweets-20160212.rds")
length(tweets)
tweets.df <- twListToDF(tweets)
tweets.df[190, c("id", "created", "screenName", "replyToSN",
"favoriteCount", "retweetCount", "longitude", "latitude", "text")]
writeLines(strwrap(tweets.df$text[190], 60))
myCorpus <- Corpus(VectorSource(tweets.df$text))
myCorpus <- tm_map(myCorpus, content_transformer(tolower))
removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeURL))
removeNumPunct <- function(x) gsub("[^[:alpha:][:space:]]*", "", x)
myCorpus <- tm_map(myCorpus, content_transformer(removeNumPunct))
# remove stopwords
myStopwords <- c(setdiff(stopwords('english'), c("r", "big")),"use", "see", "used", "via", "amp")
myCorpus <- tm_map(myCorpus, removeWords, myStopwords)
myCorpus <- tm_map(myCorpus, stripWhitespace)
myCorpusCopy <- myCorpus
myCorpus <- tm_map(myCorpus, stemDocument)
tdm <- TermDocumentMatrix(myCorpus,
control = list(wordLengths = c(1, Inf)))
tdm
idx <- which(dimnames(tdm)$Terms %in% c("r", "data", "mining"))
as.matrix(tdm[idx, 21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 20)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x=term, y=freq)) + geom_bar(stat="identity") +
xlab("Terms") + ylab("Count") + coord_flip() +
theme(axis.text=element_text(size=7))
stemCompletion2 <- function(x, dictionary)
{
x <- unlist(strsplit(as.character(x), " "))
x <- x[x != ""]
x <- stemCompletion(x, dictionary=dictionary)
x <- paste(x, sep="", collapse=" ")
PlainTextDocument(stripWhitespace(x))
}
myCorpus <- lapply(myCorpus, stemCompletion2, dictionary=myCorpusCopy)
myCorpus <- Corpus(VectorSource(myCorpus))
tdm <- TermDocumentMatrix(myCorpus,
control = list(wordLengths = c(1, Inf)))
tdm
idx <- which(dimnames(tdm)$Terms %in% c("r", "data", "mining"))
as.matrix(tdm[idx, 21:30])
(freq.terms <- findFreqTerms(tdm, lowfreq = 20))
term.freq <- rowSums(as.matrix(tdm))
term.freq <- subset(term.freq, term.freq >= 20)
df <- data.frame(term = names(term.freq), freq = term.freq)
library(ggplot2)
ggplot(df, aes(x=term, y=freq)) + geom_bar(stat="identity") +
xlab("Terms") + ylab("Count") + coord_flip() +
theme(axis.text=element_text(size=7))
#Librerías que necesita
library(limma)
library(igraph)
library(glasso)
library(reshape2)
library(plyr)
setwd("/home/arabinov/doctorado/programacion/redes_mixtas/")
setwd("~/doctorado/programacion/redes_mixtas/")
source("pipeline/funciones_grafos.R")
(load("pipeline_archivos/reguladores.Rdata"))
(load("pipeline_archivos/2_genes_prefiltrados.Rdata"))
(load("pipeline_archivos/3_transcriptoma.Rdata"))
(load("pipeline_archivos/4_bines_prefiltrados.Rdata"))
(load("pipeline_archivos/5_spliceoma.Rdata"))
(load("pipeline_archivos/6_red_mixta.Rdata"))
proteinas_relacionadas_con_splicing <- unique(c(poi$SP, reguladores$gene_id[reguladores$tipo_de_regulador=="RBP" | reguladores$tipo_de_regulador=="NO CLASIFICADOS"]))
g_ego <- g
perfiles_bines  <- perfiles_bines[rownames(perfiles_bines) %in% names(V(g_ego)), ]
perfiles_genes  <- perfiles_genes[c(sample(rownames(perfiles_genes), 0), intersect(rownames(perfiles_genes), names(V(g_ego)))), ]
proteinas_relacionadas_con_splicing <- intersect(rownames(perfiles_genes), proteinas_relacionadas_con_splicing)
ft                                  <- intersect(rownames(perfiles_genes), reguladores_de_expresion)
sd   <- apply(perfiles_genes, 1, sd)
m    <- apply(perfiles_genes, 1, mean)
z    <- (perfiles_genes - m)/sd
sd   <- apply(perfiles_bines, 1, sd)
m    <- apply(perfiles_bines, 1, mean)
zb   <- (perfiles_bines - m)/sd
ccov <- cov(t(rbind(z, zb)))
hist(cov(t(z)), main="Cov Genes")
hist(cov(t(zb)), main="Cov Bines")
penalizaciones <- matrix(ncol=ncol(ccov), nrow=nrow(ccov), 1)
colnames(penalizaciones)                     <- colnames(ccov)
rownames(penalizaciones)                     <- rownames(ccov)
enlaces <- ends(g_ego, E(g_ego))
bines_conectados <- c()
for(i in 1:ecount(g_ego)){
tipo <- grep(":", enlaces[i, ])
if(length(tipo) == 0){
tipo = "gg"
}else if(length(tipo) == 1){
tipo = "gb"
if(length(grep(":", enlaces[i, 1])) == 1){
bines_conectados <- c(bines_conectados, enlaces[i, 1])
}else{
bines_conectados <- c(bines_conectados, enlaces[i, 2])
}
}else{
tipo = "bb"
}
penalizaciones[enlaces[i, 1], enlaces[i, 2]] <- tipo
penalizaciones[enlaces[i, 2], enlaces[i, 1]] <- tipo
}
bines_conectados <- unique(bines_conectados)
stars <- function(ccov, penalizaciones, pasos = 1000, subsample_ratio = NULL, beta = 0.1, numero_de_repeticiones = 20){
n <- nrow(ccov)
if(is.null(subsample_ratio)){
if(n > 144){
subsample_ratio = 10*sqrt(n)/n
}else{
subsample_ratio = 0.8
}
}
b = round(subsample_ratio*n)
paths <- vector("list", length=numero_de_repeticiones)
for(i in 1:numero_de_repeticiones){
print(paste0("Subsample ", i, " de ", numero_de_repeticiones))
subsample <- sample(1:n, replace = FALSE, size = b)
paths[[i]] <- barrido_glasso(ccov[subsample, subsample], penalizaciones[subsample, subsample], pasos, verbose = T)
paths[[i]] <- lapply(paths[[i]], function(p){
completa <- matrix(0, ncol=n, nrow=n)
completa[subsample, subsample] <- p
return(completa)
})
}
inestabilidades <- vector("list", length=pasos)
for(i in 1:pasos){
tita <- matrix(0, ncol=n, nrow=n)
for(j in 1:numero_de_repeticiones){
tita <- tita + paths[[j]][[i]]
}
tita <- tita/numero_de_repeticiones
seda <- 2*tita*(1-tita)
inestabilidades[[i]] <- sum(seda[upper.tri(seda)])/choose(b, 2)
}
inestabilidades <- unlist(inestabilidades)
inestabilidades_monotonizado <- inestabilidades
for(i in length(inestabilidades_monotonizado):1){
inestabilidades_monotonizado[i] <- max(inestabilidades_monotonizado[i:length(inestabilidades_monotonizado)])
}
return(inestabilidades_monotonizado)
}
median_gb <- median(abs(ccov[penalizaciones == "gb"]))
median_gg <- median(abs(ccov[penalizaciones == "gg"]))
median_bb <- median(abs(ccov[penalizaciones == "bb"]))
lambda_gg <- median_gg/median_gb
lambda_bb <- median_bb/median_gb
median_bb
mean(abs(ccov[penalizaciones == "bb"]))
lambda_gg <- median_gg/median_gb
lambda_bb <- median_bb/median_gb
lambda_gg
lambda_bb
barrido_glasso <- function(ccov, penalizaciones, pasos = 1000, verbose = TRUE){
rho                        <- matrix(ncol=ncol(ccov), nrow=nrow(ccov), 1)
rho[penalizaciones == "1"] <- 1
path <- vector("list", length=pasos)
i = 1
start       <- "cold"
for(penalizacion in seq(0.1, 1, length.out = length(path))){
if(verbose == TRUE & i %% round(0.1*pasos) == 0){
print(paste0("Barrido ", i, " de ", pasos))
}
#rho[penalizaciones != "1"] <- penalizacion
rho[penalizaciones == "gg"] <- lambda_gg*penalizacion
rho[penalizaciones == "bb"] <- lambda_bb*penalizacion
rho[penalizaciones == "gb"] <- penalizacion
me        <- glasso(ccov, rho=rho, thr = 1e-4, start = start, w.init = me$w, wi.init = me$wi)
path[[i]] <- ifelse(me$wi!=0 & row(me$wi)!=col(me$wi), 1, 0)
colnames(path[[i]]) <- rownames(path[[i]]) <- rownames(ccov)
start     <- "warm"
i = i + 1
}
return(path)
}
g_glasso <- barrido_glasso(ccov, penalizaciones, pasos = 1000)
#Glasso no es simétrica
g_melteada <- melt(as.matrix(as_adj(as.undirected(g_ego))))
g_melteada <- g_melteada[g_melteada$value != 0, 1:2]
interseccion_a <- rep(0, length(g_glasso))
interseccion_b <- rep(0, length(g_glasso))
tamano_g_glasso <- rep(0, length(g_glasso))
kmax <- rep(0, length(g_glasso))
kmin <- rep(0, length(g_glasso))
#layout(matrix(1:9, ncol=3))
mm <- matrix(ncol=3, nrow=length(g_glasso))
gm<-table(unlist(apply(g_melteada, 1, function(s){return(length(grep(":", s)))})))
for(i in 1:length(g_glasso)){
print(paste("Barriendo", tipo, "con lambda", i/length(g_glasso)))
glasso_melteada <- melt(g_glasso[[i]])
glasso_melteada <- glasso_melteada[glasso_melteada$value != 0, 1:2]
tamano_g_glasso[i] <- nrow(glasso_melteada)
interseccion_a[i]  <- nrow(match_df(g_melteada, glasso_melteada))
if(i %% round(0.01*length(g_glasso)) == 0){
grid.newpage();
draw.pairwise.venn(nrow(g_melteada), tamano_g_glasso[i], interseccion_a[i], category = c(paste("Expresión", i), "Glasso"), filename = NULL, main="a")
}
interseccion_b[i] <- interseccion_a[i]/tamano_g_glasso[i]
interseccion_a[i] <- interseccion_a[i]/nrow(g_melteada)
ggm<-table(unlist(apply(glasso_melteada, 1, function(s){return(length(grep(":", s)))})))
mm[i, 1] <- ggm["0"]/gm["0"]
mm[i, 2] <- ggm["1"]/gm["1"]
mm[i, 3] <- ggm["2"]/gm["2"]
k <- table(glasso_melteada[, 1])[bines_conectados]+table(glasso_melteada[, 2])[bines_conectados]
#k2 <- table(g_melteada[, 1])[bines_conectados]+table(g_melteada[, 2])[bines_conectados]
kmax[i] <- max(k)
kmin[i] <- sum(k == 0)
}
plot(kmax, xlab="1/lambda", ylab="k")
points(kmin, col="red")
abline(v=which.max(kmin != 0), col="green")
abline(v=840, col="green")
abline(h=max(kmax)/2, col="green")
library(VennDiagram)
#Glasso no es simétrica
g_melteada <- melt(as.matrix(as_adj(as.undirected(g_ego))))
g_melteada <- g_melteada[g_melteada$value != 0, 1:2]
interseccion_a <- rep(0, length(g_glasso))
interseccion_b <- rep(0, length(g_glasso))
tamano_g_glasso <- rep(0, length(g_glasso))
kmax <- rep(0, length(g_glasso))
kmin <- rep(0, length(g_glasso))
#layout(matrix(1:9, ncol=3))
mm <- matrix(ncol=3, nrow=length(g_glasso))
gm<-table(unlist(apply(g_melteada, 1, function(s){return(length(grep(":", s)))})))
for(i in 1:length(g_glasso)){
print(paste("Barriendo", tipo, "con lambda", i/length(g_glasso)))
glasso_melteada <- melt(g_glasso[[i]])
glasso_melteada <- glasso_melteada[glasso_melteada$value != 0, 1:2]
tamano_g_glasso[i] <- nrow(glasso_melteada)
interseccion_a[i]  <- nrow(match_df(g_melteada, glasso_melteada))
if(i %% round(0.01*length(g_glasso)) == 0){
grid.newpage();
draw.pairwise.venn(nrow(g_melteada), tamano_g_glasso[i], interseccion_a[i], category = c(paste("Expresión", i), "Glasso"), filename = NULL, main="a")
}
interseccion_b[i] <- interseccion_a[i]/tamano_g_glasso[i]
interseccion_a[i] <- interseccion_a[i]/nrow(g_melteada)
ggm<-table(unlist(apply(glasso_melteada, 1, function(s){return(length(grep(":", s)))})))
mm[i, 1] <- ggm["0"]/gm["0"]
mm[i, 2] <- ggm["1"]/gm["1"]
mm[i, 3] <- ggm["2"]/gm["2"]
k <- table(glasso_melteada[, 1])[bines_conectados]+table(glasso_melteada[, 2])[bines_conectados]
#k2 <- table(g_melteada[, 1])[bines_conectados]+table(g_melteada[, 2])[bines_conectados]
kmax[i] <- max(k)
kmin[i] <- sum(k == 0)
}
plot(kmax, xlab="1/lambda", ylab="k")
points(kmin, col="red")
abline(v=which.max(kmin != 0), col="green")
abline(v=840, col="green")
abline(h=max(kmax)/2, col="green")
plot(kmax, xlab="1/lambda", ylab="k")
points(kmin, col="red")
abline(v=which.max(kmin != 0), col="green")
abline(v=840, col="green")
abline(h=max(kmax)/2, col="green")
abline(v=830, col="green")
abline(h=max(kmax)/2, col="green")
plot(kmax, xlab="1/lambda", ylab="k")
points(kmin, col="red")
#abline(v=which.max(kmin != 0), col="green")
abline(v=830, col="green")
abline(h=max(kmax)/2, col="green")
max(kmax)/2
matplot(mm, type="b", pch=".")
abline(h=0.5, col="blue")
which(mm[, 1] == 0.5)
which(mm[, 2] == 0.5)
which(mm[, 3] == 0.5)
which(near(mm[, 3], 0.5))
getwd()
save.image(file="glasso.RData")
